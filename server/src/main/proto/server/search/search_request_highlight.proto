/*
 * SPDX-License-Identifier: Apache-2.0
 *
 * The OpenSearch Contributors require contributions made to
 * this file be licensed under the Apache-2.0 license or a
 * compatible open source license.
 */

/*
  OpenSearch _core API

  OpenSearch _core API

  The version of the OpenAPI document: 1.0.0

  Generated by OpenAPI Generator: https://openapi-generator.tech
*/

syntax = "proto3";

package org.opensearch.search.proto;
option java_multiple_files = true;

import "server/search/query_container.proto";
import "google/protobuf/any.proto";

message SearchRequestHighlight {

  HighlightBase base = 1;

  enum EncoderEnum {
    DEFAULT = 0;
    HTML = 1;
  }

  EncoderEnum encoder = 2;

  // [required]
  map<string, HighlightFields> fields = 3;

}

message HighlightBase {
  enum TypeEnum {
    FVH = 0;
    PLAIN = 1;
    UNIFIED = 2;
  }

  TypeEnum type = 1;

  // A string that contains each boundary character.
  string boundary_chars = 2;

  // How far to scan for boundary characters.
  int32 boundary_max_scan = 3;

  enum Boundary_scannerEnum {
    CHARS = 0;
    SENTENCE = 1;
    WORD = 2;
  }

  Boundary_scannerEnum boundary_scanner = 4;

  // Controls which locale is used to search for sentence and word boundaries. This parameter takes a form of a language tag, for example: `\"en-US\"`, `\"fr-FR\"`, `\"ja-JP\"`.
  string boundary_scanner_locale = 5;

  bool force_source = 6;

  enum FragmenterEnum {
    SIMPLE = 0;
    SPAN = 1;
  }

  FragmenterEnum fragmenter = 7;

  // The size of the highlighted fragment in characters.
  int32 fragment_size = 8;

  bool highlight_filter = 9;

  QueryContainer highlight_query = 10;

  int32 max_fragment_length = 11;

  // If set to a non-negative value, highlighting stops at this defined maximum limit. The rest of the text is not processed, thus not highlighted and no error is returned The `max_analyzed_offset` query setting does not override the `index.highlight.max_analyzed_offset` setting, which prevails when it's set to lower value than the query setting.
  int32 max_analyzed_offset = 12;

  // The amount of text you want to return from the beginning of the field if there are no matching fragments to highlight.
  int32 no_match_size = 13;

  // The maximum number of fragments to return. If the number of fragments is set to `0`, no fragments are returned. Instead, the entire field contents are highlighted and returned. This can be handy when you need to highlight short texts such as a title or address, but fragmentation is not required. If `number_of_fragments` is `0`, `fragment_size` is ignored.
  int32 number_of_fragments = 14;

  /*
         options:
          type: object
          additionalProperties:
            type: object
  */
  map<string, google.protobuf.Any> options = 175733092;

  enum OrderEnum {
    SCORE = 0;
  }

  OrderEnum order = 15;

  // Controls the number of matching phrases in a document that are considered. Prevents the `fvh` highlighter from analyzing too many phrases and consuming too much memory. When using `matched_fields`, `phrase_limit` phrases per matched field are considered. Raising the limit increases query time and consumes more memory. Only supported by the `fvh` highlighter.
  int32 phrase_limit = 16;

  // Use in conjunction with `pre_tags` to define the HTML tags to use for the highlighted text. By default, highlighted text is wrapped in `<em>` and `</em>` tags.
  repeated string post_tags = 17;

  // Use in conjunction with `post_tags` to define the HTML tags to use for the highlighted text. By default, highlighted text is wrapped in `<em>` and `</em>` tags.
  repeated string pre_tags = 18;

  // By default, only fields that contains a query match are highlighted. Set to `false` to highlight all fields.
  bool require_field_match = 19;

  enum Tags_schemaEnum {
    STYLED = 0;
  }

  Tags_schemaEnum tags_schema = 20;

}

message HighlightFields {

  HighlightBase base = 1;

  int32 fragment_offset = 2;

  repeated string matched_fields = 3;

  HighlightAnalyzer analyzer = 4;

}

message HighlightAnalyzer {

  enum TypeEnum {
    CUSTOM = 0;
    FINGERPRINT = 1;
    KEYWORD = 2;
    LANGUAGE = 3;
    NORI = 4;
    PATTERN = 5;
    SIMPLE = 6;
    STANDARD = 7;
    STOP = 8;
    WHITESPACE = 9;
    ICU_ANALYZER = 10;
    KUROMOJI = 11;
    SNOWBALL = 12;
    DUTCH = 13;
  }

  TypeEnum type = 1;

  repeated string char_filter = 2;

  repeated string filter = 3;

  float position_increment_gap = 4;

  float position_offset_gap = 5;

  string tokenizer = 6;

  string version = 7;

  float max_output_size = 8;

  bool preserve_original = 9;

  string separator = 10;

  repeated string stopwords = 11;

  string stopwords_path = 12;

  LanguageEnum language = 13;

  repeated string stem_exclusion = 14;

  enum Decompound_modeEnum {
    DISCARD = 0;
    MIXED = 1;
    NONE = 2;
  }

  Decompound_modeEnum decompound_mode = 15;

  repeated string stoptags = 16;

  string user_dictionary = 17;

  string flags = 18;

  bool lowercase = 19;

  string pattern = 20;

  float max_token_length = 21;

  enum MethodEnum {
    NFC = 0;
    NFKC = 1;
    NFKC_CF = 2;
  }

  MethodEnum method = 22;

  enum ModeEnum {
    EXTENDED = 0;
    NORMAL = 1;
    SEARCH = 2;
  }

  ModeEnum mode = 23;
}


enum LanguageEnum {
  ARMENIAN = 0;
  BASQUE = 1;
  CATALAN = 2;
  DANISH = 3;
  DUTCH = 4;
  ENGLISH = 5;
  FINNISH = 6;
  FRENCH = 7;
  GERMAN = 8;
  GERMAN2 = 9;
  HUNGARIAN = 10;
  ITALIAN = 11;
  KP = 12;
  LOVINS = 13;
  NORWEGIAN = 14;
  PORTER = 15;
  PORTUGUESE = 16;
  ROMANIAN = 17;
  RUSSIAN = 18;
  SPANISH = 19;
  SWEDISH = 20;
  TURKISH = 21;
}
